{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14882264-020f-44ab-aa59-3739d2e28ba3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": "# Lab 3: Streaming - Respostas em Tempo Real\n\n<img src=\"./assets/LC_streaming.png\" width=\"400\">\n\n## ðŸŽ¯ O que vocÃª vai aprender neste Lab\n\n**Streaming** reduz a latÃªncia percebida pelo usuÃ¡rio, entregando dados assim que sÃ£o gerados pelo modelo, em vez de esperar a resposta completa.\n\n### Por que Streaming Ã© importante?\n\n1. **Melhor UX**: UsuÃ¡rios veem progresso imediato (como no ChatGPT)\n2. **Menor latÃªncia percebida**: Primeira palavra aparece rapidamente\n3. **Feedback visual**: UsuÃ¡rio sabe que o sistema estÃ¡ trabalhando\n4. **AplicaÃ§Ãµes interativas**: Essencial para chatbots e assistentes\n\n### Modos de Streaming no LangChain:\n\n| Modo | DescriÃ§Ã£o | Uso |\n|------|-----------|-----|\n| `values` | Retorna apÃ³s cada passo do agente | Debug, visualizar ciclo ReAct |\n| `messages` | Token por token | Chatbots, UX responsiva |\n| `custom` | Dados customizados de tools | Progresso de operaÃ§Ãµes longas |"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "514707c4-454b-40f4-a66c-977e6a5f51c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": "## âš™ï¸ Setup - ConfiguraÃ§Ã£o do Ambiente"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0aede07-672f-42f9-a400-5b99f405ae5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": "InstalaÃ§Ã£o das bibliotecas necessÃ¡rias."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e76fada0-78bb-4c33-aee6-8be1c56eab66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "%pip install -U mlflow>=3 langchain>=1 langchain-community langgraph databricks-langchain --quiet\ndbutils.library.restartPython()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9fc4dc7-f025-4b0a-9671-87bbc8f9bb7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "from langchain.agents import create_agent"
  },
  {
   "cell_type": "code",
   "source": "import mlflow\nmlflow.langchain.autolog()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f6ddbc3-c7df-4318-ace5-61e298fa58dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "from databricks_langchain import ChatDatabricks\n\n# Inicializar o modelo Databricks\nllm = ChatDatabricks(\n    endpoint=\"databricks-meta-llama-3-3-70b-instruct\",\n    temperature=0.1,\n)\n\nagent = create_agent(\n    model=llm,\n    system_prompt=\"You are a full-stack comedian\",\n)"
  },
  {
   "cell_type": "markdown",
   "source": "## Criando o Agente de Teste\n\nVamos criar um agente simples para demonstrar os diferentes modos de streaming.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6bcab468-0d6e-47bf-9800-5962e078d325",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": "## ðŸš« Sem Streaming (`invoke`)\n\nPrimeiro, vamos ver como Ã© **sem streaming**. O mÃ©todo `invoke()` espera a resposta completa antes de retornar.\n\n**Problema**: O usuÃ¡rio nÃ£o vÃª nada atÃ© que toda a resposta esteja pronta. Para respostas longas, isso pode parecer lento."
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be5dbca7-bdad-4f85-bb26-26feedc6f5cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke\"}]})\n",
    "print(result[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "124b349f-cdec-4594-91ff-279a8333c9fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": "## ðŸ“Š Modo `values` - Streaming por Passos\n\nEste Ã© o modo que usamos nos exemplos anteriores. Retorna dados **apÃ³s cada passo** do ciclo ReAct:\n- ApÃ³s o modelo raciocinar\n- ApÃ³s uma tool ser chamada\n- ApÃ³s a resposta final\n\n**Ideal para**: Debug, visualizar o fluxo de trabalho do agente, entender o raciocÃ­nio."
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c113f0d-2f19-4cd9-bdbd-b36b79d80da2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Stream = values\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a Dad joke\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fddb7ca6-105c-43a4-8101-ca197711b959",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": "## âš¡ Modo `messages` - Token por Token\n\nEste Ã© o modo mais responsivo! Retorna cada token assim que Ã© gerado pelo LLM.\n\n**Ã‰ exatamente assim que ChatGPT e Claude funcionam** - vocÃª vÃª as palavras aparecendo uma a uma.\n\n**Ideal para**: Chatbots, interfaces conversacionais, qualquer aplicaÃ§Ã£o onde UX responsiva Ã© importante."
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8aaae58-b683-4d48-998a-a4a775df72f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Write me a family friendly poem.\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(f\"{token.content}\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "346a22f8-32a3-43a5-8b81-916a1509e5e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": "## ðŸ”§ Modo `custom` - Streaming de Tools\n\nTools tambÃ©m podem fazer streaming! Isso Ã© Ãºtil quando uma ferramenta executa uma operaÃ§Ã£o demorada e vocÃª quer mostrar progresso ao usuÃ¡rio.\n\n### Como funciona:\n1. Use `get_stream_writer()` dentro da tool\n2. Chame `writer(\"mensagem\")` para enviar dados\n3. Use `stream_mode=[\"custom\"]` para receber esses dados\n\n**Ideal para**: \n- OperaÃ§Ãµes longas (downloads, processamento)\n- Feedback de progresso\n- Log de etapas intermediÃ¡rias"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e592ff4-5cba-46cb-9ec1-746a8ac71be1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "from langchain.agents import create_agent\nfrom langgraph.config import get_stream_writer\n\n\ndef get_weather(city: str) -> str:\n    \"\"\"Get weather for a given city.\"\"\"\n    writer = get_stream_writer()\n    # stream any arbitrary data\n    writer(f\"Looking up data for city: {city}\")\n    writer(f\"Acquired data for city: {city}\")\n    return f\"It's always sunny in {city}!\"\n\n\nagent_weather = create_agent(\n    model=llm,\n    tools=[get_weather],\n)\n\nfor chunk in agent_weather.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n    stream_mode=[\"values\", \"custom\"],\n):\n    print(chunk)"
  },
  {
   "cell_type": "markdown",
   "source": "### Usando apenas o modo `custom`\n\nVocÃª pode filtrar para receber apenas os dados customizados da tool:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9d823e4-dded-4da0-aaad-8478eac54b3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "## ðŸŽ® Sua Vez - Experimente!\n\nCombine diferentes modos de streaming e filtre os resultados como preferir.\n\n### Filtrando apenas dados custom:\n\nQuando vocÃª usa mÃºltiplos modos, cada chunk vem como uma tupla `(modo, dados)`. VocÃª pode filtrar:"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e94d4c6b-5bb5-4b86-bc53-d8ed5b2f879b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Try different modes on your own!\n",
    "Modify the stream mode and the select to produce different results."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸ“š Resumo e PrÃ³ximos Passos\n\n### O que aprendemos:\n\n| MÃ©todo | Modo | LatÃªncia | Uso |\n|--------|------|----------|-----|\n| `invoke()` | Nenhum | Alta | OperaÃ§Ãµes batch |\n| `stream(mode=\"values\")` | Por passo | MÃ©dia | Debug, visualizaÃ§Ã£o |\n| `stream(mode=\"messages\")` | Por token | Baixa | Chatbots, UX |\n| `stream(mode=\"custom\")` | Customizado | VariÃ¡vel | Progresso de tools |\n\n### Dicas:\n- Use `messages` para a melhor experiÃªncia do usuÃ¡rio\n- Use `values` para debugging e entender o agente\n- Use `custom` para operaÃ§Ãµes longas em tools\n- Combine modos quando precisar de diferentes informaÃ§Ãµes\n\n### PrÃ³ximo Lab:\nNo **Lab 4 - Tools**, vocÃª aprenderÃ¡ a criar ferramentas mais sofisticadas com descriÃ§Ãµes detalhadas e comportamentos customizados!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "134b9b2c-a894-4562-b63c-6d09113a1357",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "for chunk in agent_weather.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n    stream_mode=[\"values\", \"custom\"],\n):\n    if chunk[0] == \"custom\":\n        print(chunk[1])"
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "L3_streaming",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}