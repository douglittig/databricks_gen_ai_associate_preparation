# Demo Batch

**Source:** `Generative AI Application Deployment and Monitoring - Demo Batch.mp4`
**Duration:** 16:07
**Language:** en (detected with 100.0% confidence)

---

## Full Transcription

So again enough said, and let's show you an action how you can go through that batch deployment pipeline in Databricks by doing that on a small language model, why small language model because in our lab environment and your lab environment, it's not guaranteed to have access to GPUs so to just make it easy on everyone will be focusing on a small model, but you can definitely apply that same approach to any sized model assuming you have access to the correct sizeable hardware. Once we'll get that model from hugging phase, we are going to log it to unity catalogs model registry as a new version and from that point on we'll show how one can schedule batch inference jobs using that model using the spark QDF. And then we'll also conclude by showcasing how the AI query can be used as well for batch inference on an existing foundation model that has already been deployed on the Databricks serving infrastructure. Let's jump into the Databricks environment and open our first demo notebook called batch inference as a lamp for small language models. So what we're going to do here is first prepare a data set. Now here the assumption of the data set is that it has already been created for you. It is the batch. It is a table containing all the input text that we want to summarize because here in our case the use case that we're doing is we're going to do a batch inference job to summarize a bunch of text that we have pulled from the extreme summarization or ex some data set from hugging phase. So that's what we're doing here in a nutshell. We are loading the data set from hugging phase and creating a data frame on top and writing it back materializing it to a delta table called m41 prod data. And that table will so contain the difference. So if I do a quick SQL statement, select all from we call it m41 prod data. I should be able to see all the different text that I do want to summarize as part of my batch job. Here we go. So here we have the documents. Now here we have the ground through summary that are provided by the data set, but this is what we're going to run our inference on. So the assumption is that you have a job again, which is ingesting the new text that these observations are stored in a delta table somewhere. So let's go about creating the model using the vanilla workflow. I'm going to get the model from a hugging phase or the T5 small, which is a text to sex transformer and create a pipeline on top of that. Again, if you're not familiar with what a pipeline is, again, this is not a crash course on hugging phase transformers, but it's very easy to pick up. Whenever you create a pipeline, you give it a task. You can define a model tokenizer and a bunch of inference-related parameters, such as maybe the minimum length of a summary, the length, do I want to do any truncation doing some sampling, so add some randomness device maps. Normally, if you don't set it, it will be set to auto mean if there is a GPU available, the summarization will run on a GPU. If not, it will fall back to CPU. Now that the summarizer has been created, let's do a quick test on some random text on a some random artist called JPEG Mafia. So here I can see that I was able to summarize the original text. Now that I have my pipeline ready, the next step would be to create an experiment and log that specific pipeline with its corresponding hyper parameters. So in order to do that and the metadata related, so it is always a best practice to give in to infer the signature of the model, such as the XPI will expose the signature. And for any type of specific flavor, so here for the transformer flavor, we are going to generate a signal output. So it is always a good practice to create a model signature by using the infer signature method. So how the signature works, you just feed it an input and feed it, what the output assuming this output was already generated by your models. So we define all these metadata information, we are going point to any specific experiment name, and we are also going to log some additional parameters. Here ultimately you could be logging some other information, you could be logging some evaluation metrics, you could be running a couple of things. But here just for the sake of simplicity, we're just showing how we're going to log this model using the MLflow transformer log API. So you provided the summarizer, the artifact pass, which is just the name of the folder where you want all the binary files to be created, inference configuration, when this model will be used, whether for batch or real time, and the signature and an input example. So once this command, once we do this logging to the model, what is going to happen is we will see that a new MLflow experiment is going to be created and that a transformer model has been logged. So let's take a quick peek at what was created inside that experiment. So I can see that I have an overview that as part of that specific experiment using having this random name, I have logged the transformer model with a bunch of parameters, no metrics because we didn't do any evaluations. And if I go to my artifact to see what was created, so I can see that the model schema has been grabbed so the input the output, some code snippets on how I could use this model to make prediction either on a spark data frame or pandas data frame. And the different let's say binary files, so the components, the tokenizer, the metadata, the model information itself, like the safe tensors, which containing the weight of my model, and all the additional information, like a model card, because it's coming from hugging phase or again, if you want to create a model yourself locally, and once you push it to the hugging phase hub, you want the model card to be populated, you could do that. So all these things are automatically logged for you using the MLflow transformer flavor, so going back to our two to our demo. Now here we only created one X, we just created one model, logged it once did you do any specific evaluation, but let's say you're running this, because what we're emulating here in that same notebook is the whole process, usually creating the chain or getting the model or maybe potentially fine tuning it will be running on its own. Then logging it then you would have an additional job to evaluate it, but let's say you the evaluation has been made and then you have an additional job, which will automatically won't programmatically figure out get me the artifact for maybe the latest experiment. So here what I'm doing here using the MLflow API is I'm searching my run given my experiment name, usually the experiment multiple jobs could be pointing to the same experiment ID or everyone having its own. So I'm just going to programmatically get the location of the model that was created as part of that specific experiment. And that's what will allow you to programmatically search the or query the tracking server using some specific specific like search criteria here. We're just doing a simple search run and we're sorting by the start time, but you can also search runs and sort them given some specific metrics, which were logged as well as part of the model. And so now that I have my model you are I how can I load it back for example and do some batch quote unquote inference on a single node so you can load it back using the load model from the MLflow Python flavor and that will automatically expose the predict method. And so it will just re log back the full pipeline and you can automatically use it in a single node fashion on some text. So here I'm just going to run my summary again and I can see the summary of the biography of Mr Hendricks. Now that predict method can also accept a pandas series or a list so you can do some sort of batch, but it will be executed row by row. So we got the model from hugging phase we created an experiment where we logs experiment specific parameters and all the model artifacts assuming that okay we're happy with this model and we want to push it down the path for the LLM ops cycle. This is where we would register the model to unity catalog and once the model will be registered it's always going to be registered on the specific catalog schema and a model name that you provide it will automatically get if the model that doesn't exist it will create an initial version of it and it will create without the alias that we can set either via the UI or programmatically. So just for a sake of time i'm just going to showcase how one can do these actions programmatically so here what i'm doing i'm telling it. The model created as part of that specific experiment that we search programmatically register it to the data break unity catalog model registry again we can do this via UI via the experiment but think about how to do things programmatically and automate things. You would use the ml flow API methods to do that and so here it's telling me that the model successfully registered under this my catalog my schema and the summarizer and here if I just go to my catalog i will be able to see that the under my specific catalog and the schema default i have now a new model my summarizer created here. That is version one of it and again i can tag it it's going to be called the academy etc product the academy save the tags and what not so you can search model by tags as well and aliases but let's go back and see how we could set that alias programmatically as well we show how to put the tag via the UI but you can also set that alias. So here for that we are going to use the ml flow tracking client and the set register model or alias API so what we're going to do we're going to get the latest model version and give it the champion alias so with that why do we need to do that it's because when things are going to run in a production to do batch inference you are going to invoke the model name by either it's a given version or it's alias. And let's show that in action so first thing first is to load back in a spark data frame what are the inputs on which we want to do the summarization on so the list of documents on which we want to summarize thing and it is that delta table that we created using the X some data set previously. So in order to do single node batch inference as we said you could do load the model back so using its specific you are right so here we are going to pull the model back from the registry using the latest current model version that we calculated previously so once you with the ml flow pipe punk load model we are reloading back the latest model as you can see as an ml flow pipe function riser which has the ml flow transformer flavor. So now that we have that pipeline back in our memory we could it will expose a predict method which is what the Python method will expose and we can use the predict method again to do some batch inference on for example here i'm just. Just taking a small samples putting it back in the pandas data frame because we're doing things single nodes so again you can provide a pandas data frame or pandas series or a list some i'm turning i'm just taking two samples putting it in the pandas data frame and feeding it the first. Two documents as a series to the predict method and I can see my two summarizations here and here now let's talk about how we can scale the batch inference using a spark qdf so for that. We are going to leverage the ml flow pipe punk dot spark udf method and the way that what this udf is expecting is a model you are i so here i'm telling it i want to create a user defined function which is nothing more than running the predict method at scale in a multi note fashion on a batch on a spark data frame and i'm forcing it to have the result type output as a string. Once we created that udf called production model udf that's where we can apply it at scale to our pandas data frame using the pi spark formalism so what we're doing here and this is where ultimately summarizing job will be executed we are creating a new colon called generated summary on which we are going to apply that udf to the input documents colon. And that's it once the job once we execute that depending on the cluster where you're running your job if it's a single node cluster it's going to run on a single node if it has multiple node spark will partition the different documents send up to the different corresponding workers and each worker will run the summarization on its own partition and. And as we wait for the summarizing job to finish the last step that we that is usually a recommended step to do once the batch inference job has been completed is to materialize back the output to a specific table so here we are going to materialize the output of the summarization job into a new table called m41 underscore batch inference and that's it so let's take a quick look at the generated summaries which are here. And we are going to materialize the outputs from the spark data frame into a new delta table that we will call batch inference and this is where you can pick up the result or your downstream applications or stakeholders can get the result from this batch job that's it now as a side note another data breaks intelligence platform capability that you can use in order to run batch inferences on a language. Which model is the a i query so as we presented in the lecture earlier it is a sequel so it is a sequel method as part of the runtime it supports foundation models that are already made available on the data breaks serving infrastructure here where we will be using the defects instruct for example and i'm going to tell it to for example run when instruct the model. To provide a summary in less than 100 word for every documents provided from my production data table so if I try to execute that and i'm asking it to materialize the result in a new delta table that we are going to call a i query inference so waiting a couple of seconds for the batch job to finish what's going to happen here under the hood is that for every observations in the table a request will be made to the phone. Condition models API hosting the data bricks DB rex instruct and the outputs are going to be stored back in the generated summary column so here I can see the summaries that were provided by data bricks DB rex or any model that you have served on your model serving endpoint so that concludes the demo on batch inference.

---

## Timestamped Segments

**[00:00]** So again enough said, and let's show you an action how you can go through that batch deployment pipeline in Databricks by doing that on a small language model, why small language model because in our lab environment and your lab environment, it's not guaranteed to have access to GPUs so to just make it easy on everyone will be focusing on a small model, but you can definitely apply that same approach to any sized model assuming you have access to the correct sizeable hardware.

**[00:29]** Once we'll get that model from hugging phase, we are going to log it to unity catalogs model registry as a new version and from that point on we'll show how one can schedule batch inference jobs using that model using the spark QDF.

**[00:43]** And then we'll also conclude by showcasing how the AI query can be used as well for batch inference on an existing foundation model that has already been deployed on the Databricks serving infrastructure.

**[00:57]** Let's jump into the Databricks environment and open our first demo notebook called batch inference as a lamp for small language models.

**[01:05]** So what we're going to do here is first prepare a data set. Now here the assumption of the data set is that it has already been created for you.

**[01:14]** It is the batch. It is a table containing all the input text that we want to summarize because here in our case the use case that we're doing is we're going to do a batch inference job to summarize a bunch of text that we have pulled from the extreme summarization or ex some data set from hugging phase.

**[01:34]** So that's what we're doing here in a nutshell. We are loading the data set from hugging phase and creating a data frame on top and writing it back materializing it to a delta table called m41 prod data.

**[01:49]** And that table will so contain the difference. So if I do a quick SQL statement, select all from we call it m41 prod data. I should be able to see all the different text that I do want to summarize as part of my batch job.

**[02:07]** Here we go. So here we have the documents. Now here we have the ground through summary that are provided by the data set, but this is what we're going to run our inference on.

**[02:17]** So the assumption is that you have a job again, which is ingesting the new text that these observations are stored in a delta table somewhere.

**[02:26]** So let's go about creating the model using the vanilla workflow. I'm going to get the model from a hugging phase or the T5 small, which is a text to sex transformer and create a pipeline on top of that.

**[02:39]** Again, if you're not familiar with what a pipeline is, again, this is not a crash course on hugging phase transformers, but it's very easy to pick up.

**[02:49]** Whenever you create a pipeline, you give it a task. You can define a model tokenizer and a bunch of inference-related parameters, such as maybe the minimum length of a summary, the length, do I want to do any truncation doing some sampling, so add some randomness device maps.

**[03:05]** Normally, if you don't set it, it will be set to auto mean if there is a GPU available, the summarization will run on a GPU. If not, it will fall back to CPU.

**[03:15]** Now that the summarizer has been created, let's do a quick test on some random text on a some random artist called JPEG Mafia. So here I can see that I was able to summarize the original text.

**[03:28]** Now that I have my pipeline ready, the next step would be to create an experiment and log that specific pipeline with its corresponding hyper parameters.

**[03:41]** So in order to do that and the metadata related, so it is always a best practice to give in to infer the signature of the model, such as the XPI will expose the signature.

**[03:55]** And for any type of specific flavor, so here for the transformer flavor, we are going to generate a signal output.

**[04:01]** So it is always a good practice to create a model signature by using the infer signature method.

**[04:08]** So how the signature works, you just feed it an input and feed it, what the output assuming this output was already generated by your models.

**[04:17]** So we define all these metadata information, we are going point to any specific experiment name, and we are also going to log some additional parameters.

**[04:27]** Here ultimately you could be logging some other information, you could be logging some evaluation metrics, you could be running a couple of things.

**[04:33]** But here just for the sake of simplicity, we're just showing how we're going to log this model using the MLflow transformer log API.

**[04:42]** So you provided the summarizer, the artifact pass, which is just the name of the folder where you want all the binary files to be created, inference configuration, when this model will be used, whether for batch or real time, and the signature and an input example.

**[04:59]** So once this command, once we do this logging to the model, what is going to happen is we will see that a new MLflow experiment is going to be created and that a transformer model has been logged.

**[05:13]** So let's take a quick peek at what was created inside that experiment.

**[05:19]** So I can see that I have an overview that as part of that specific experiment using having this random name, I have logged the transformer model with a bunch of parameters, no metrics because we didn't do any evaluations.

**[05:35]** And if I go to my artifact to see what was created, so I can see that the model schema has been grabbed so the input the output, some code snippets on how I could use this model to make prediction either on a spark data frame or pandas data frame.

**[05:49]** And the different let's say binary files, so the components, the tokenizer, the metadata, the model information itself, like the safe tensors, which containing the weight of my model, and all the additional information, like a model card, because it's coming from hugging phase or again, if you want to create a model yourself locally, and once you push it to the hugging phase hub, you want the model card to be populated, you could do that.

**[06:14]** So all these things are automatically logged for you using the MLflow transformer flavor, so going back to our two to our demo.

**[06:22]** Now here we only created one X, we just created one model, logged it once did you do any specific evaluation, but let's say you're running this, because what we're emulating here in that same notebook is the whole process, usually creating the chain or getting the model or maybe potentially fine tuning it will be running on its own.

**[06:41]** Then logging it then you would have an additional job to evaluate it, but let's say you the evaluation has been made and then you have an additional job, which will automatically won't programmatically figure out get me the artifact for maybe the latest experiment.

**[06:57]** So here what I'm doing here using the MLflow API is I'm searching my run given my experiment name, usually the experiment multiple jobs could be pointing to the same experiment ID or everyone having its own.

**[07:09]** So I'm just going to programmatically get the location of the model that was created as part of that specific experiment.

**[07:17]** And that's what will allow you to programmatically search the or query the tracking server using some specific specific like search criteria here.

**[07:27]** We're just doing a simple search run and we're sorting by the start time, but you can also search runs and sort them given some specific metrics, which were logged as well as part of the model.

**[07:38]** And so now that I have my model you are I how can I load it back for example and do some batch quote unquote inference on a single node so you can load it back using the load model from the MLflow Python flavor and that will automatically expose the predict method.

**[07:54]** And so it will just re log back the full pipeline and you can automatically use it in a single node fashion on some text. So here I'm just going to run my summary again and I can see the summary of the biography of Mr Hendricks.

**[08:10]** Now that predict method can also accept a pandas series or a list so you can do some sort of batch, but it will be executed row by row.

**[08:18]** So we got the model from hugging phase we created an experiment where we logs experiment specific parameters and all the model artifacts assuming that okay we're happy with this model and we want to push it down the path for the LLM ops cycle.

**[08:36]** This is where we would register the model to unity catalog and once the model will be registered it's always going to be registered on the specific catalog schema and a model name that you provide it will automatically get if the model that doesn't exist it will create an initial version of it and it will create without the alias that we can set either via the UI or programmatically.

**[09:00]** So just for a sake of time i'm just going to showcase how one can do these actions programmatically so here what i'm doing i'm telling it.

**[09:10]** The model created as part of that specific experiment that we search programmatically register it to the data break unity catalog model registry again we can do this via UI via the experiment but think about how to do things programmatically and automate things.

**[09:26]** You would use the ml flow API methods to do that and so here it's telling me that the model successfully registered under this my catalog my schema and the summarizer and here if I just go to my catalog i will be able to see that the under my specific catalog and the schema default i have now a new model my summarizer created here.

**[09:50]** That is version one of it and again i can tag it it's going to be called the academy etc product the academy save the tags and what not so you can search model by tags as well and aliases but let's go back and see how we could set that alias programmatically as well we show how to put the tag via the UI but you can also set that alias.

**[10:21]** So here for that we are going to use the ml flow tracking client and the set register model or alias API so what we're going to do we're going to get the latest model version and give it the champion alias so with that why do we need to do that it's because when things are going to run in a production to do batch inference you are going to invoke the model name by either it's a given version or it's alias.

**[10:52]** And let's show that in action so first thing first is to load back in a spark data frame what are the inputs on which we want to do the summarization on so the list of documents on which we want to summarize thing and it is that delta table that we created using the X some data set previously.

**[11:12]** So in order to do single node batch inference as we said you could do load the model back so using its specific you are right so here we are going to pull the model back from the registry using the latest current model version that we calculated previously so once you with the ml flow pipe punk load model we are reloading back the latest model as you can see as an ml flow pipe function riser which has the ml flow transformer flavor.

**[11:42]** So now that we have that pipeline back in our memory we could it will expose a predict method which is what the Python method will expose and we can use the predict method again to do some batch inference on for example here i'm just.

**[11:59]** Just taking a small samples putting it back in the pandas data frame because we're doing things single nodes so again you can provide a pandas data frame or pandas series or a list some i'm turning i'm just taking two samples putting it in the pandas data frame and feeding it the first.

**[12:16]** Two documents as a series to the predict method and I can see my two summarizations here and here now let's talk about how we can scale the batch inference using a spark qdf so for that.

**[12:29]** We are going to leverage the ml flow pipe punk dot spark udf method and the way that what this udf is expecting is a model you are i so here i'm telling it i want to create a user defined function which is nothing more than running the predict method at scale in a multi note fashion on a batch on a spark data frame and i'm forcing it to have the result type output as a string.

**[12:58]** Once we created that udf called production model udf that's where we can apply it at scale to our pandas data frame using the pi spark formalism so what we're doing here and this is where ultimately summarizing job will be executed we are creating a new colon called generated summary on which we are going to apply that udf to the input documents colon.

**[13:23]** And that's it once the job once we execute that depending on the cluster where you're running your job if it's a single node cluster it's going to run on a single node if it has multiple node spark will partition the different documents send up to the different corresponding workers and each worker will run the summarization on its own partition and.

**[13:44]** And as we wait for the summarizing job to finish the last step that we that is usually a recommended step to do once the batch inference job has been completed is to materialize back the output to a specific table so here we are going to materialize the output of the summarization job into a new table called m41 underscore batch inference and that's it so let's take a quick look at the generated summaries which are here.

**[14:14]** And we are going to materialize the outputs from the spark data frame into a new delta table that we will call batch inference and this is where you can pick up the result or your downstream applications or stakeholders can get the result from this batch job that's it now as a side note another data breaks intelligence platform capability that you can use in order to run batch inferences on a language.

**[14:44]** Which model is the a i query so as we presented in the lecture earlier it is a sequel so it is a sequel method as part of the runtime it supports foundation models that are already made available on the data breaks serving infrastructure here where we will be using the defects instruct for example and i'm going to tell it to for example run when instruct the model.

**[15:12]** To provide a summary in less than 100 word for every documents provided from my production data table so if I try to execute that and i'm asking it to materialize the result in a new delta table that we are going to call a i query inference so waiting a couple of seconds for the batch job to finish what's going to happen here under the hood is that for every observations in the table a request will be made to the phone.

**[15:42]** Condition models API hosting the data bricks DB rex instruct and the outputs are going to be stored back in the generated summary column so here I can see the summaries that were provided by data bricks DB rex or any model that you have served on your model serving endpoint so that concludes the demo on batch inference.

