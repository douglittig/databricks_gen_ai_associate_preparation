# Slide 1: Prompt Engineering Primer

**LECTURE**

### Prompt Engineering Primer

**Databricks Academy**

In this lecture, we will discuss the Prompt Engineering Primer, including the basics of prompt formulation, different prompting strategies, key tips for guiding models, and the benefits and limitations of each approach.

---

# Slide 2: Prompt Basics

**Definitions**

*   **Prompt**: An AI prompt is an input or query given to a large language model to elicit a specific response or output.
*   **Prompt Engineering**: Prompt engineering is the practice of designing and refining prompts to optimize the responses generated by AI models.

**Speaker Notes:**
A prompt is the input or query provided to a large language model or AI model, usually in natural language, that the model processes in order to generate a response. Prompt engineering involves designing these prompts thoughtfully, similar to how one might explain a concept differently depending on the listener’s age or background. For large language models, the clarity and context within a prompt determine how well the model understands and responds to a question or task. By giving more relevant information in the prompt, the model can provide better answers. Prompt engineering is therefore the practice of creating and refining prompts to optimize the quality of responses from these AI systems.

**References:**
*   [What is Retrieval Augmented Generation (RAG)? | Databricks](https://www.databricks.com/glossary/retrieval-augmented-generation-rag)
*   [A Survey of Techniques for Maximizing LLM Performance](https://arxiv.org/abs/2312.16171)

---

# Slide 3: Prompt Basics

**Prompt components**

A good prompt usually consists of:
*   **Instruction**: A clear directive that specifies what the model should do.
*   **Context**: Background/additional information that provides the necessary details to understand the task.
*   **Input / question**: The specific query or data that the model needs to process.
*   **Output type / format**: The desired structure or style of the response generated by the model.

*(Slide includes an example showing a prompt with these components labeled)*

**Speaker Notes:**
Some basic elements of a good prompt for large language models have been identified by those working extensively with these systems. First, a prompt should provide a clear instruction that specifies what the model is expected to do, such as summarizing or generating content. Adding context is important, as it gives the model necessary background information to understand the task—for example, making sure it understands whether "orchestration" refers to IT or music. The prompt should also include the input or the specific question for the model to address. Defining the output type or format, such as asking for a summary in three bullet points written in Markdown, helps guide the model’s response. By including all these pieces—instruction, context, input, and output format—a prompt is more likely to yield a relevant and high-quality answer.

---

# Slide 4: Prompt Engineering Techniques

*(Title Slide)*

**Speaker Notes:**
There are many techniques in prompt engineering beyond just giving instructions and context. Prompt engineering involves exploring different ways to provide these elements and guide the model. By varying how instructions and context are presented, it’s possible to influence the model towards producing better answers. This shows that crafting prompts is not limited to basic pieces but also includes creative strategies for guiding AI responses.

---

# Slide 5: Zero-shot / Few-shot Prompting

**Using or not-using an example**

### Zero-shot Prompting
*   Prompt that generates text or perform a task **without providing any examples** or additional training specific to that task.

### Few-shot Prompting
*   Prompt provides with **a few input-output examples** to guide the model for generating the desired output.

*(Slide includes visual examples of Zero-shot vs Few-shot prompts)*

**Speaker Notes:**
Some common techniques in prompt engineering include zero-shot and few-shot prompting. Zero-shot prompting is when the model is asked to perform a task without being given any examples, relying solely on the instruction provided. Few-shot prompting, on the other hand, involves supplying the model with a few examples to help it better understand the task at hand. This approach is especially useful in tasks like sentiment analysis, where examples can guide the model’s response. In zero-shot, the instruction alone is used, whereas in few-shot, the model receives sample inputs and outputs before completing a new task. Both methods are widely used to elicit better outcomes from AI models.

---

# Slide 6: Prompting Chaining

**Break tasks into subtasks**

*   Multiple tasks are linked together, with the output of one prompt serving as the input for the next.
*   This method allows for more complex tasks to be broken down into manageable steps.

*(Slide includes a diagram of prompt chaining flow)*

**Speaker Notes:**
Another technique is prompt chaining, which is useful when asking models to handle complex tasks. Instead of expecting the model to complete a complicated task in one step, the task can be divided into smaller subtasks. For example, rather than having the model immediately summarize an entire article, it may first be asked to find the most important quotes in the document. The output from this step can then be used as input for further steps, advancing the conversation and processing. This approach breaks down the task and guides the model through each stage, making it easier to achieve the desired outcome.

---

# Slide 7: Chain-of-Thought Prompting

**"Let’s think step-by-step"**

*   Chain-of-thought (CoT) prompting enhances the reasoning capabilities of LLMs by guiding them to **articulate their thought processes step-by-step**, similar to human reasoning.
*   Research in this area has **mixed findings**;
    *   Some research showed that simply asking the model to think step-by-step helps to solve reasoning questions.
    *   Others showed that models don't follow CoT faithfully (Paper 1, Paper 2, Paper 3).

*(Slide includes examples of CoT prompts vs standard prompts)*

**Speaker Notes:**
Another method is chain-of-thought prompting, where the model is encouraged to reason step by step rather than just providing a direct answer. Some models are capable of doing this when explicitly asked, which is especially useful for tasks that involve logical reasoning or solving math problems. For example, if a question involves calculating the number of bananas in a bakery, prompting the model to work out the solution step by step can lead to a more accurate result. This technique leverages the model's ability to process and solve problems incrementally. Chain-of-thought prompting is a common approach for more advanced reasoning tasks that require careful breakdown and explanation.

---

# Slide 8: Prompt Engineering Tips & Tricks

*(Title Slide)*

**Speaker Notes:**
Retrieval-augmented generation is a technique or method in the context of developing Large Language Models (LLMs) with supplemental information. The method involves using an LLM or other generative AI model to generate responses using context retrieved from an external knowledge store, such as a vector database. This allows the LLM to generate more informed and contextually relevant outputs.

---

# Slide 9: Tip: Prompts are model-specific

**A prompt guides the model to complete task(s)**

*   Different models may require **different prompts**.
*   Provide **examples and cues** to guide model’s response generation.
*   Different **use cases** may require different prompts.
*   **Iterative development** is key.
    *   Iterate by adjusting the **temperature parameter**—higher for more creative outputs, lower for focused responses.
*   Be aware of **bias and hallucination**.

**Speaker Notes:**
Different models can interpret prompts in unique ways, so a prompt that works well for one model might not perform as effectively on another. It’s important to experiment with both prompts and parameters like temperature while remaining mindful of potential bias or hallucinations in the responses.

---

# Slide 10: Tip: Format prompts

*   **Use delimiters to distinguish between instruction and context**
    *   Pound sign `###`
    *   Backticks ```
    *   Braces / brackets `{}` / `[]`
    *   Dashes `---`
*   **Ask the model to return structured output**
    *   HTML, json, table, markdown, etc.
*   **Provide a correct example**
    *   "Return the movie name mentioned in the form of a Python dictionary. The output should look like `{'Title': 'In and Out'}`"

*(Slide includes an example prompt using delimiters)*

**Speaker Notes:**
Formatting prompts by adding structure, such as using delimiters like pound signs or braces, helps models better distinguish context and instructions. It's also common to request structured outputs like HTML, JSON, tables, or Markdown, often by providing a clear example so the model understands the expected response.

---

# Slide 11: Tip: Guide the model for better responses

*   **Ask the model not to make things up/hallucinate**
    *   "Do not make things up if you do not know. Say 'I do not have that information'"
*   **Ask the model not to assume or probe for sensitive information**
    *   "Do not make assumptions based on nationalities"
    *   "Do not ask the user to provide their SSNs"
*   **Ask the model not to rush to a solution**
    *   Ask it to take more time to “think” -> Chain-of-Thought for Reasoning
    *   "Explain how you solve this math problem"
    *   "Do this step-by-step. Step 1: Summarize into 100 words. Step 2: Translate from English to French..."

**Speaker Notes:**
Guiding the model to better responses can involve adding a system prompt or directive to set clear instructions, such as telling the model not to fabricate information or avoid assumptions that can cause bias or data leakage. It's also helpful to remind the model not to give out personal information and, when appropriate, to request that it use step-by-step reasoning with chain-of-thought prompts.

---

# Slide 12: Benefits and Limitations

### Benefits
*   **Simple and efficient**: The time taken to generate the ideal results is significantly low.
*   **Predictable results**: Consistently generate results that meet predefined standards for accuracy.
*   **Tailored outputs**: Customization of AI responses to fit specific needs or styles.

### Limitations
*   The output depends on used model.
*   Limited by pre-trained model's internal knowledge. **For external knowledge we need to use RAG.**

**Speaker Notes:**
Prompt engineering is a simple and efficient way to get started with large language models, since anyone with access to a chat interface can experiment and achieve predictable results without needing software engineering skills. However, its limitations come from the need to fit everything within the prompt and the model’s capabilities, so if a task requires external information, prompt engineering alone may not be enough.
